{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### table of content\n",
    "1) [Load samples](#load-samples)\n",
    "2) [Metrics](#metrics)\n",
    "3) [Performances computation](#performances-computation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies and general utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import open3d as o3d\n",
    "import laspy\n",
    "import pdal\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import cKDTree\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_preds = r\"..\\data\\flattening_corrections\\predictions\"\n",
    "src_gt = r\"..\\data\\flattening_corrections\\gt\"\n",
    "src_floors = r\"..\\data\\flattening_corrections\\floors\"\n",
    "src_masks = r\"..\\data\\flattening_corrections\\masks\"\n",
    "src_originals = r\"..\\data\\flattening_corrections\\originals\"\n",
    "src_flatten = r\"..\\data\\flattening_corrections\\flatten\"\n",
    "src_results = r\"..\\data\\flattening_corrections\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_preds = {}\n",
    "list_masks = {}\n",
    "list_floors = {}\n",
    "list_flatten = {}\n",
    "list_floors = {}\n",
    "list_gt = {}\n",
    "list_originals = {}\n",
    "\n",
    "samples_num = [128, 129, 160, 210, 311, 633]\n",
    "tilling_num = [0, 1, 5, 10, 20]\n",
    "\n",
    "for r, _, f in os.walk(src_preds):\n",
    "    for num in samples_num:\n",
    "        list_preds[num] = [os.path.join(r, file) for file in f if len(file.split(str(num))) > 1]\n",
    "for r, _, f in os.walk(src_masks):\n",
    "    for num in samples_num:\n",
    "        list_masks[num] = [os.path.join(r, file) for file in f if len(file.split(str(num))) > 1]\n",
    "for r, _, f in os.walk(src_floors):\n",
    "    for num in samples_num:\n",
    "        list_floors[num] = [os.path.join(r, file) for file in f if len(file.split(str(num))) > 1]\n",
    "for r, _, f in os.walk(src_flatten):\n",
    "    for num in samples_num:\n",
    "        list_flatten[num] = [os.path.join(r, file) for file in f if len(file.split(str(num))) > 1]\n",
    "for r, _, f in os.walk(src_originals):\n",
    "    for num in samples_num:\n",
    "        list_originals[num] = [os.path.join(r, file) for file in f if len(file.split(str(num))) > 1][0]\n",
    "for r, _, f in os.walk(src_gt):\n",
    "    for num in samples_num:\n",
    "        list_gt[num] = [os.path.join(r, file) for file in f if len(file.split(str(num))) > 1][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_panoptic_quality(gt_instances, pred_instances):\n",
    "    \"\"\"\n",
    "    Computes Panoptic Quality (PQ), Segmentation Quality (SQ), and Recognition Quality (RQ).\n",
    "    \n",
    "    :param gt_instances: List of sets, each containing point indices for a ground truth instance.\n",
    "    :param pred_instances: List of sets, each containing point indices for a predicted instance.\n",
    "    :return: PQ, SQ, RQ\n",
    "    \"\"\"\n",
    "\n",
    "    # gt_instances, pred_instances = get_segmentation(gt_instances, pred_instances)\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    iou_sum = 0\n",
    "\n",
    "    # Match predicted instances to ground truth instances\n",
    "    matched_gt = set()\n",
    "    matched_pred = set()\n",
    "    \n",
    "    for i, gt in enumerate(gt_instances):\n",
    "        best_iou = 0\n",
    "        best_pred = None\n",
    "\n",
    "        for j, pred in enumerate(pred_instances):\n",
    "            iou = len(gt & pred) / len(gt | pred)  # IoU computation\n",
    "            \n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_pred = j\n",
    "        \n",
    "        # Threshold for a valid match\n",
    "        if best_iou > 0.5:\n",
    "            matched_gt.add(i)\n",
    "            matched_pred.add(best_pred)\n",
    "            tp += 1\n",
    "            iou_sum += best_iou\n",
    "        else:\n",
    "            fn += 1  # Unmatched ground truth instance\n",
    "    \n",
    "    fp = len(pred_instances) - len(matched_pred)  # Unmatched predictions\n",
    "\n",
    "    RQ = tp / (tp + 0.5 * (fp + fn)) if (tp + 0.5 * (fp + fn)) > 0 else 0\n",
    "    SQ = iou_sum / tp if tp > 0 else 0\n",
    "    PQ = SQ * RQ\n",
    "\n",
    "    return PQ, SQ, RQ, tp, fp, fn\n",
    "\n",
    "\n",
    "def compute_mean_iou(y_true, y_pred, num_classes=2):\n",
    "    \"\"\"\n",
    "    Computes mean Intersection over Union (mIoU).\n",
    "    \n",
    "    :param y_true: Ground truth labels (N,)\n",
    "    :param y_pred: Predicted labels (N,)\n",
    "    :param num_classes: Total number of classes\n",
    "    :return: Mean IoU score\n",
    "    \"\"\"\n",
    "    iou_list = []\n",
    "    \n",
    "    for c in range(num_classes):\n",
    "        tp = np.sum((y_true == c) & (y_pred == c))\n",
    "        fp = np.sum((y_true != c) & (y_pred == c))\n",
    "        fn = np.sum((y_true == c) & (y_pred != c))\n",
    "        \n",
    "        iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0\n",
    "        iou_list.append(iou)\n",
    "\n",
    "    return np.mean(iou_list)\n",
    "\n",
    "\n",
    "def get_segmentation(instance_list, semantic_list):\n",
    "    instances_format = []\n",
    "    semantic_format = []\n",
    "    # Computing instances\n",
    "    for instance in set(instance_list):\n",
    "        if instance == 0: continue\n",
    "        list_points = [pos for pos, val in enumerate(instance_list) if val == instance]\n",
    "        instances_format.append(set(list_points))\n",
    "\n",
    "    # Computing semantic\n",
    "    for semantic in set(semantic_list):\n",
    "        list_points = [pos for pos, val in enumerate(semantic_list) if val == semantic]\n",
    "        semantic_format.append(set(list_points))\n",
    "\n",
    "    return instances_format, semantic_format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performances computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(laz_file):\n",
    "    # Find pairs of points\n",
    "    coords = np.round(np.vstack((laz_file.x, laz_file.y, laz_file.z)),2).T\n",
    "    tree_B = cKDTree(coords)\n",
    "    pairs = tree_B.query_pairs(1e-2)\n",
    "\n",
    "    # Create the mask with dupplicates\n",
    "    mask = [True for i in range(len(coords))]\n",
    "    for pair in pairs:\n",
    "        mask[pair[1]] = False\n",
    "\n",
    "    # Remove the dupplicates from the file\n",
    "    laz_file.points = laz_file.points[mask]\n",
    "\n",
    "\n",
    "def match_pointclouds(laz1, laz2):\n",
    "    \"\"\"Sort laz2 to match the order of laz1 without changing laz1's order.\n",
    "\n",
    "    Args:\n",
    "        laz1: laspy.LasData object (reference order)\n",
    "        laz2: laspy.LasData object (to be sorted)\n",
    "    \n",
    "    Returns:\n",
    "        laz2 sorted to match laz1\n",
    "    \"\"\"\n",
    "    # Retrieve and round coordinates for robust matching\n",
    "    coords_1 = np.round(np.vstack((laz1.x, laz1.y, laz1.z)), 2).T\n",
    "    coords_2 = np.round(np.vstack((laz2.x, laz2.y, laz2.z)), 2).T\n",
    "\n",
    "    # Verify laz2 is of the same size as laz1\n",
    "    assert len(coords_2) == len(coords_1), \"laz2 should be a subset of laz1\"\n",
    "\n",
    "    # Create a dictionary mapping from coordinates to indices\n",
    "    coord_to_idx = {tuple(coord): idx for idx, coord in enumerate(coords_1)}\n",
    "\n",
    "    # Find indices in laz1 that correspond to laz2\n",
    "    matching_indices = []\n",
    "    failed = 0\n",
    "    for coord in coords_2:\n",
    "        try:\n",
    "            matching_indices.append(coord_to_idx[tuple(coord)])\n",
    "        except Exception as e:\n",
    "            failed += 1\n",
    "    # print(f\"Number of non-matching points: {failed}\")\n",
    "\n",
    "    matching_indices = np.array([coord_to_idx[tuple(coord)] for coord in coords_2])\n",
    "\n",
    "    # Sort laz2 to match laz1\n",
    "    sorted_indices = np.argsort(matching_indices)\n",
    "\n",
    "    # Apply sorting to all attributes of laz2\n",
    "    laz2.points = laz2.points[sorted_indices]\n",
    "\n",
    "    return laz2  # Now sorted to match laz1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing on all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle\n",
    "metrics = ['PQ', 'SQ', 'RQ', 'mIoU', 'Recall', 'Precision']\n",
    "metrics_res = {samp_num: np.zeros((len(samples_num), len(tilling_num))) for samp_num in samples_num}\n",
    "\n",
    "for i, samp_num in tqdm(enumerate(samples_num), total=len(samples_num)):\n",
    "    original_src = list_originals[samp_num]\n",
    "    gt_src = list_gt[samp_num]\n",
    "    laz_original = laspy.read(original_src)\n",
    "\n",
    "    for j, tilling in enumerate(tilling_num):\n",
    "        if tilling > 0:\n",
    "            pred_src = [x for x in list_preds[samp_num] if len(x.split(f'{tilling}m')) > 1][0]\n",
    "            floor_src = [x for x in list_floors[samp_num] if len(x.split(f'{tilling}m')) > 1][0]\n",
    "            flatten_src = [x for x in list_flatten[samp_num] if len(x.split(f'{tilling}m')) > 1][0]\n",
    "            mask_src = [x for x in list_masks[samp_num] if len(x.split(f'{tilling}m')) > 1][0]\n",
    "        else:\n",
    "            pred_src = [x for x in list_preds[samp_num] if len(os.path.basename(x).split('flatten')) == 1][0]\n",
    "            flatten_src = original_src\n",
    "\n",
    "        laz_pred = laspy.read(pred_src)\n",
    "        laz_gt = laspy.read(gt_src)\n",
    "        laz_flatten = laspy.read(flatten_src)\n",
    "\n",
    "        laz_pred = match_pointclouds(laz_flatten, laz_pred)\n",
    "\n",
    "        pred_coords = np.vstack((laz_pred.x, laz_pred.y, laz_pred.z)).T\n",
    "        gt_coords = np.vstack((laz_gt.x, laz_gt.y, laz_gt.z)).T\n",
    "\n",
    "        remove_duplicates(laz_gt)\n",
    "        laz_gt = match_pointclouds(laz_original, laz_gt)\n",
    "\n",
    "        # Crop groud truth\n",
    "        if len(os.path.basename(pred_src).split('flatten')) > 1:\n",
    "            # add floor to preds\n",
    "            laz_floor = laspy.read(floor_src)\n",
    "            floor_coords = np.vstack((laz_floor.x, laz_floor.y, laz_floor.z)).T\n",
    "            pred_coords[:,2] = pred_coords[:,2] + floor_coords[:,2]\n",
    "            setattr(laz_pred, 'x', pred_coords[:,0])\n",
    "            setattr(laz_pred, 'y', pred_coords[:,1])\n",
    "            setattr(laz_pred, 'z', pred_coords[:,2])\n",
    "\n",
    "            # load mask\n",
    "            with open(mask_src, 'rb') as infile:\n",
    "                mask = pickle.load(infile)\n",
    "            laz_gt.points = laz_gt.points[mask]\n",
    "            laz_gt = match_pointclouds(laz_pred, laz_gt)\n",
    "\n",
    "        # Compute metrics\n",
    "        gt_instances = laz_gt.gt_instance_segmentation\n",
    "        gt_semantic = laz_gt.gt_semantic_segmentation\n",
    "        pred_instances = laz_pred.PredInstance\n",
    "        pred_semantic = laz_pred.PredSemantic\n",
    "\n",
    "        gt_instances_format, gt_semantic_format = get_segmentation(gt_instances, gt_semantic)\n",
    "        pred_instances_format, pred_semantic_format = get_segmentation(pred_instances, pred_semantic)\n",
    "        \n",
    "        PQ, SQ, RQ, tp, fp, fn = compute_panoptic_quality(gt_instances_format, pred_instances_format)\n",
    "        mean_iou = compute_mean_iou(gt_semantic, pred_semantic)\n",
    "        metrics_res[samp_num][0,j] = PQ\n",
    "        metrics_res[samp_num][1,j] = SQ\n",
    "        metrics_res[samp_num][2,j] = RQ\n",
    "        metrics_res[samp_num][3,j] = mean_iou\n",
    "        metrics_res[samp_num][4,j] = round(tp/(tp + fn), 2) if tp + fn > 0 else 0\n",
    "        metrics_res[samp_num][5,j] = round(tp/(tp + fp),2) if tp + fp > 0 else 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics_res.keys():\n",
    "    print(metric)\n",
    "    print(metrics_res[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sampnum_to_terrain = {\n",
    "    128: \"light slope sample\",\n",
    "    129: \"bushes sample\",\n",
    "    160: \"slope empty sample\",\n",
    "    210: \"flat empty sample\",\n",
    "    311: \"flat sample\",\n",
    "    633: \"heavy slope sample\"\n",
    "}\n",
    "fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "for pos, samp_num in enumerate(samples_num):\n",
    "    i = pos//3\n",
    "    j = pos%3\n",
    "    arr_res = metrics_res[samp_num]\n",
    "    df_data = pd.DataFrame(\n",
    "        data=arr_res,\n",
    "        columns=tilling_num,\n",
    "        index=metrics\n",
    "    )\n",
    "    max_mask = df_data.eq(df_data.max(axis=1), axis=0)\n",
    "    annot_colors = np.full(df_data.shape, \"black\", dtype=object)  # Default text color\n",
    "    annot_colors[max_mask] = \"red\"  # Set highest values to red\n",
    "\n",
    "    sns.heatmap(data=df_data, cmap=\"crest\", annot=True, ax=axs[i,j], fmt=\".2f\")\n",
    "    axs[i,j].set_title(dict_sampnum_to_terrain[samp_num])\n",
    "\n",
    "    # Draw only horizontal grid lines\n",
    "    axs[i,j].hlines(np.arange(1, df_data.shape[0]), *axs[i,j].get_xlim(), color=\"white\", linewidth=0.8)\n",
    "\n",
    "    # Color the highest values in red\n",
    "    for text, (k, l) in zip(axs[i,j].texts, np.ndindex(df_data.shape)):\n",
    "        text.set_color('black')\n",
    "        if max_mask.iat[k, l]:  \n",
    "            text.set_fontsize(12)  # Set the highest value in each row to red\n",
    "            text.set_fontweight('bold')  # Set the highest value in each row to red\n",
    "        else:\n",
    "            text.set_fontsize(10)  # Default color\n",
    "    if i == 1:\n",
    "        axs[i,j].set_xlabel('Grid size [m]')\n",
    "    if j == 0:\n",
    "        axs[i,j].set_ylabel('Metric [-]')\n",
    "plt.suptitle(\"Flattening results for different grid sizes\")\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PDM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
